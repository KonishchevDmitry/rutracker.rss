#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Receives new torrents info from http://rutracker.org/ and stores them into the
database.
"""

import cookielib
import getopt
import logging
import os
import re
import sys
import tempfile
import time
import urllib2

import pycl.daemon
import pycl.log
import pycl.main
import pycl.misc

from pycl.core import Error, LogicalError
from pycl.misc import to_system_encoding

import rutracker.torrents

LOG = logging.getLogger("rutracker.rss")

_DEVELOP_MODE = False
"""True if the script is running in develop mode."""

_SCRIPT_PATH = os.path.realpath(__file__)
"""Full path to this script."""


class Rutracker:
    """Fetches pages from http://rutracker.org/."""

    __opener = None
    """A URL opener."""

    __search_id = None
    """Active search ID."""

    __search_page = None
    """Active search page."""

    __last_request_time = 0
    """Last request time."""


    def search(self, page):
        """Returns the specified torrent search page."""

        if self.__search_id is None:
            self.__start_search()

        if not page:
            return self.__search_page

        return self.__request("http://rutracker.org/forum/tracker.php?search_id={search_id}&start={start}".format(
            search_id = self.__search_id, start = page * 50))


    def __login(self):
        """Logins to rutracker.org."""

        try:
            credentials_path = os.path.join(os.path.dirname(_SCRIPT_PATH), "credentials")
            login, password = ( string.strip() for string in open(credentials_path).read().strip().split("\n") )

            cookies = cookielib.FileCookieJar("cookies")
            opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookies))

            opener.open("http://login.rutracker.org/forum/login.php",
                "login_username={0}&login_password={1}&login=%C2%F5%EE%E4".format(login, password))

            self.__opener = opener
        except Exception as e:
            raise Error("Unable to login to rutracker.org: {0}.", e)


    def __request(self, url, data = None):
        """Sends a request."""

        if self.__opener is None:
            self.__login()

        max_per_second = 1
        min_difference = 1.0 / max_per_second
        if time.time() - self.__last_request_time < min_difference:
            time.sleep(self.__last_request_time + min_difference - time.time())

        try:
            return self.__opener.open(url, data).read().decode("cp1251")
        except Exception as e:
            raise Error("Unable to fetch page {0}: {1}.", url, e)
        finally:
            self.__last_request_time = time.time()


    def __start_search(self):
        """Starts torrent search."""

        try:
            page = self.__request("http://rutracker.org/forum/tracker.php",
                data = "prev_my=0&prev_new=0&prev_oop=0&f%5B%5D=709&f%5B%5D=46&f%5B%5D=2076&f%5B%5D=98&f%5B%5D=56&f%5B%5D=2123&f%5B%5D=249&f%5B%5D=552&f%5B%5D=500&f%5B%5D=1260&f%5B%5D=2139&o=1&s=2&tm=-1&pn=&nm=&submit=%CF%EE%E8%F1%EA")

            match = re.search(r'<a class="pg" href="tracker.php\?search_id=([^&]+)', page)
            if match is None:
                raise Error("Unable to obtain search id")

            self.__search_id = match.group(1)
            self.__search_page = page
        except Exception as e:
            raise Error("Failed to start torrent search: {0}.", e)



def get_new_torrents():
    """Gets new torrents info."""

    LOG.info(u"Search for new torrents...")

    # A regular expression for attribute name
    attribute_name_regex = "[a-zA-Z][-.a-zA-Z0-9:_]*"

    # A regular expression for tag attributes
    tag_attrs_regex = re.sub(r"\s*", "", r"""
        (?:\s+
          """ + attribute_name_regex + r"""
          (?:\s*=\s*
            (?:
              '[^']*'
              |"[^"]*"
              |[^'"/>\s]+
            )
          )?
        )*
    """)

    def tag_regex(tag, tag_class = None, match_param = None, match_value = """([^'"]*)"""):
        """A reqular expression that matches the specified tag."""

        regex = "<" + tag + tag_attrs_regex

        if tag_class is not None:
            regex += r"""\s+class\s*=\s*['"]\s*(?:[^'" ]+\s+)*{0}(?:\s+[^'" ]+)*\s*['"]""".format(tag_class)
            regex += tag_attrs_regex

        if match_param is not None:
            regex += ur"""\s+{0}\s*=\s*['"]{1}['"]""".format(match_param, match_value)
            regex += tag_attrs_regex

        return regex + r"\s*>"

    # A regular expression for a link to torrent page on http://rutracker.org/
    torrent_regex = re.compile(
        tag_regex("a", "tLink", "href", r"""[^'"]+/viewtopic\.php\?t=(\d+)""") + r"(.+?)</a>"
        ".+?" +
        tag_regex("td", match_param = "title", match_value = u"Добавлен") + r"\s*<u>\s*(\d+)\s*</u>",
        re.IGNORECASE | re.DOTALL | re.VERBOSE)

    # A reqular expression that matches torrent description on its page
    torrent_description_regex = re.compile(
        tag_regex("div", "post_body") +
        "(.+?)" +
        tag_regex("fieldset", "attach") + r"\s*" +
            tag_regex("legend") + r"\s*Download\s*</legend>", re.IGNORECASE | re.DOTALL)


    if not _DEVELOP_MODE:
        client = Rutracker()

    pages_to_scan = 1
    torrents_per_page = 50
    total_torrents = pages_to_scan * torrents_per_page

    for page in xrange(0, pages_to_scan):
        LOG.info(u"Getting page %s...", page)

        if _DEVELOP_MODE:
            torrents_page = open("./debug/{0}.html".format(page + 1)).read().decode("cp1251")
        else:
            torrents_page = client.search(page)

        # Scan all pages every time. It's not safe to skip them by last torrent
        # ID in the database because some of them might be hidden at the
        # previous run.

        counter = 0

        for page_torrent_id, torrent_html in enumerate(torrents_page.split('<tr class="tCenter hl-tr">')[1:]):
            torrent_id, torrent_name, torrent_time = torrent_regex.search(torrent_html).group(1, 2, 3)

            torrent_id = int(torrent_id)
            if _DEVELOP_MODE:
                torrent_time = time.time()
            torrent_time = int(torrent_time)

            torrent = rutracker.torrents.find_one(torrent_id)

            if (
                torrent is None or
                torrent["name"] != torrent_name or
                torrent["time"] != torrent_time
            ):
                torrent_number = page * torrents_per_page + page_torrent_id + 1
                if torrent_number >= total_torrents / 2:
                    LOG.error(
                        u"Got a new torrent after a half of the search (%s of %s). "
                        u"Consider to increase search page number.", torrent_number, total_torrents)

                new_data = {
                    "name":        torrent_name,
                    "time":        torrent_time,
                    "fingerprint": rutracker.torrents.get_fingerprint(torrent_name),
                    "description": "",
                }

                LOG.info(u"New torrent #%s:%s [%s]: %s",
                    torrent_id, new_data["time"], new_data["fingerprint"], new_data["name"])

                torrent_url = rutracker.torrents.get_url(torrent_id)

                try:
                    torrent_page = open("debug/torrent.html") if _DEVELOP_MODE else urllib2.urlopen(torrent_url)
                    torrent_page = torrent_page.read().decode("cp1251")
                except Exception as e:
                    LOG.error(u"Failed fetch torrent page %s: %s", torrent_url, e)
                else:
                    match = torrent_description_regex.search(torrent_page)

                    if match:
                        description = match.group(1)

                        description = re.sub(
                            tag_regex("span", "post-b") + "(.*?)</span>",
                            r"<b>\1</b>", description, flags = re.IGNORECASE | re.DOTALL)

                        description = re.sub(
                            tag_regex("var", "postImg", "title") + ".*?</var>",
                            r"<div><img src='\1' /></div>", description, flags = re.IGNORECASE | re.DOTALL)

                        new_data["description"] = description
                    else:
                        LOG.error(u"Unable to get description for torrent %s.", torrent_url)

                    rutracker.torrents.update(torrent_id, new_data, upsert = True)

            else:
                LOG.debug(u"Torrent #%s:%s [%s]: %s",
                    torrent_id, torrent["time"], torrent["fingerprint"], torrent["name"])

            counter += 1

        if counter != torrents_per_page:
            LOG.error(u"Error while parsing page %s: got %s torrents instead of %s",
                page, counter, torrents_per_page)


def main():
    """The script's main function."""

    pycl.main.set_environment()

    # Parsing command line arguments -->
    cron_mode = False
    debug_mode = False
    develop_mode = False

    cmd_options, args = getopt.gnu_getopt(
        sys.argv[1:], "", [
            "cron",
            "debug",
            "develop-mode",
        ])

    for option, value in cmd_options[:]:
        if option == "--cron":
            cron_mode = True
        elif option == "--debug":
            debug_mode = True
        elif option == "--develop-mode":
            develop_mode = True
        else:
            raise LogicalError()
    # Parsing command line arguments <--

    pycl.log.setup(
        debug_mode = debug_mode | develop_mode,
        level = logging.ERROR if cron_mode else None)

    global _DEVELOP_MODE
    _DEVELOP_MODE = develop_mode

    pid_file = os.path.join(tempfile.gettempdir(), "rutracker-get-new-torrents")

    try:
        pid_file_fd = pycl.daemon.acquire_pidfile(pid_file)
    except pycl.daemon.PidFileLocked as e:
        if cron_mode:
            LOG.debug(u"Exiting: %s", e)
        else:
            raise
    else:
        try:
            get_new_torrents()
        finally:
            pycl.misc.syscall_wrapper(os.close, pid_file_fd)
            pycl.misc.syscall_wrapper(os.unlink, to_system_encoding(pid_file))


if __name__ == "__main__":
    main()
