#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Receives new torrents info from http://rutracker.org/ and stores them into the
database.
"""

import cookielib
import getopt
import logging
import os
import re
import sys
import tempfile
import time
import urllib2

import pycl.daemon
import pycl.log
import pycl.main
import pycl.misc

from pycl.core import Error, LogicalError
from pycl.misc import to_system_encoding

import rutracker.torrents

LOG = logging.getLogger("rutracker.rss")

_DEVELOP_MODE = False
"""True if the script is running in develop mode."""

_SCRIPT_PATH = os.path.realpath(__file__)
"""Full path to this script."""


class Rutracker:
    """Fetches pages from http://rutracker.org/."""

    __opener = None
    """A URL opener."""

    __search_id = None
    """Active search ID."""

    __search_page = None
    """Active search page."""

    __last_request_time = 0
    """Last request time."""


    def search(self, page):
        """Returns the specified torrent search page."""

        if self.__search_id is None:
            self.__start_search()

        if not page:
            return self.__search_page

        return self.__request("http://rutracker.org/forum/tracker.php?search_id={search_id}&start={start}".format(
            search_id = self.__search_id, start = page * 50))


    def __login(self):
        """Logins to rutracker.org."""

        try:
            credentials_path = os.path.join(os.path.dirname(_SCRIPT_PATH), "credentials")
            login, password = open(credentials_path).read().strip().split("\n")

            cookies = cookielib.FileCookieJar("cookies")
            opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookies))

            opener.open("http://login.rutracker.org/forum/login.php",
                "login_username={0}&login_password={1}&login=%C2%F5%EE%E4".format(login, password))

            self.__opener = opener
        except Exception as e:
            raise Error("Unable to login to rutracker.org: {0}.", e)


    def __request(self, url, data = None):
        """Sends a request."""

        if self.__opener is None:
            self.__login()

        max_per_second = 1
        min_difference = 1.0 / max_per_second
        if time.time() - self.__last_request_time < min_difference:
            time.sleep(self.__last_request_time + min_difference - time.time())

        try:
            return self.__opener.open(url, data).read().decode("cp1251")
        except Exception as e:
            raise Error("Unable to fetch page {0}: {1}.", url, e)
        finally:
            self.__last_request_time = time.time()


    def __start_search(self):
        """Starts torrent search."""

        try:
            page = self.__request("http://rutracker.org/forum/tracker.php",
                data = "prev_my=0&prev_new=0&prev_oop=0&f%5B%5D=709&f%5B%5D=46&f%5B%5D=2076&f%5B%5D=98&f%5B%5D=56&f%5B%5D=2123&f%5B%5D=249&f%5B%5D=552&f%5B%5D=500&f%5B%5D=1260&f%5B%5D=2139&o=1&s=2&tm=-1&pn=&nm=&submit=%CF%EE%E8%F1%EA")

            match = re.search(r'<a class="pg" href="tracker.php\?search_id=([^&]+)', page)
            if match is None:
                raise Error("Unable to obtain search id")

            self.__search_id = match.group(1)
            self.__search_page = page
        except Exception as e:
            raise Error("Failed to start torrent search: {0}.", e)



def get_new_torrents():
    """Gets new torrents info."""

    LOG.info("Search for new torrents...")

    # A regular expression for attribute name
    attribute_name_regex = "[a-zA-Z][-.a-zA-Z0-9:_]*"

    # A regular expression for tag attributes
    tag_attrs_regex = re.sub(r"\s*", "", r"""
        (?:\s+
          """ + attribute_name_regex + r"""
          (?:\s*=\s*
            (?:
              '[^']*'
              |"[^"]*"
              |[^'"/>\s]+
            )
          )?
        )*
    """)

    # A regular expression for a link to torrent page on http://rutracker.org
    torrent_regex = re.compile(
        r"<a" + tag_attrs_regex + r"""
            \s+class=(?:
                "([^"]+)"|
                '([^']+)'
            )
        """
            + tag_attrs_regex + r"""\s+href\s*=\s*["'][^'"]+/viewtopic\.php\?t=(\d+)["']"""
            + tag_attrs_regex + r"\s*>(.+?)</a>"

        r".+<td" + tag_attrs_regex + ur"""\s+title=['"]Добавлен['"]""" + tag_attrs_regex + r"\s*>\s*<u>(\d+)</u>"
    , re.IGNORECASE | re.DOTALL | re.VERBOSE)

    if not _DEVELOP_MODE:
        client = Rutracker()

    for page in xrange(0, 1):
        LOG.info("Getting page %s...", page)

        if _DEVELOP_MODE:
            torrents_page = open("./debug/{0}.html".format(page + 1)).read().decode("cp1251")
        else:
            torrents_page = client.search(page)

        # Scan all pages every time. It's not safe to skip them by last torrent
        # ID in the database because some of them might be hidden at the
        # previous run.

        counter = 0
        torrents_per_page = 50

        for torrent_html in torrents_page.split('<tr class="tCenter hl-tr">')[1:]:
            link_class, torrent_id, torrent_name, torrent_time = torrent_regex.search(torrent_html).group(1, 3, 4, 5)

            link_class = link_class.split(" ")
            if "med" not in link_class or "tLink" not in link_class:
                continue

            torrent_id = int(torrent_id)
            if _DEVELOP_MODE:
                torrent_time = time.time()
            torrent_time = int(torrent_time)

            torrent = rutracker.torrents.find_one(torrent_id)

            if (
                torrent is None or
                torrent["name"] != torrent_name or
                torrent["time"] != torrent_time
            ):
                new_data = {
                    "name":        torrent_name,
                    "time":        torrent_time,
                    "fingerprint": rutracker.torrents.get_fingerprint(torrent_name),
                    "description": "",
                }

                rutracker.torrents.update(torrent_id, new_data, upsert = True)

                LOG.info(u"New torrent #%s:%s [%s]: %s",
                    torrent_id, new_data["time"], new_data["fingerprint"], new_data["name"])
            else:
                LOG.debug(u"Torrent #%s:%s [%s]: %s",
                    torrent_id, torrent["time"], torrent["fingerprint"], torrent["name"])

            counter += 1

        if counter != torrents_per_page:
            LOG.error("Error while parsing page %s: got %s torrents instead of %s",
                page, counter, torrents_per_page)


def main():
    """The script's main function."""

    pycl.main.set_environment()

    # Parsing command line arguments -->
    cron_mode = False
    debug_mode = False
    develop_mode = False

    cmd_options, args = getopt.gnu_getopt(
        sys.argv[1:], "", [
            "cron",
            "debug",
            "develop-mode",
        ])

    for option, value in cmd_options[:]:
        if option == "--cron":
            cron_mode = True
        elif option == "--debug":
            debug_mode = True
        elif option == "--develop-mode":
            develop_mode = True
        else:
            raise LogicalError()
    # Parsing command line arguments <--

    pycl.log.setup(
        debug_mode = debug_mode | develop_mode,
        level = logging.ERROR if cron_mode else None)

    global _DEVELOP_MODE
    _DEVELOP_MODE = develop_mode

    pid_file = os.path.join(tempfile.gettempdir(), "rutracker-get-new-torrents")

    try:
        pid_file_fd = pycl.daemon.acquire_pidfile(pid_file)
    except pycl.daemon.PidFileLocked as e:
        if cron_mode:
            LOG.debug(u"Exiting: %s", e)
        else:
            raise
    else:
        try:
            get_new_torrents()
        finally:
            pycl.misc.syscall_wrapper(os.close, pid_file_fd)
            pycl.misc.syscall_wrapper(os.unlink, to_system_encoding(pid_file))


if __name__ == "__main__":
    main()
