#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Receives new torrents info from http://rutracker.org/ and stores them into the
database.
"""

import cookielib
import logging
import re
import sys
import time
import urllib2

import pycl.log
import pycl.main
from pycl.core import Error

import rutracker.analysis
from rutracker.db import coll

LOG = logging.getLogger("rutracker.rss")

_DEVELOP_MODE = False
"""True if the script is running in develop mode."""


class Rutracker:
    """Fetches pages from http://rutracker.org/."""

    __opener = None
    """A URL opener."""

    __search_id = None
    """Active search ID."""

    __last_request_time = 0
    """Last request time."""


    def search(self, page):
        """Returns the specified torrent search page."""

        if self.__search_id is None:
            self.__start_search()

        url = "http://rutracker.org/forum/tracker.php?search_id={search_id}&start={start}".format(
            search_id = self.__search_id, start = page * 50)

        return self.__request(url)


    def __login(self):
        """Logins to rutracker.org."""

        try:
            login, password, _ = open("debug/login").read().split("\n")

            cookies = cookielib.FileCookieJar("cookies")
            opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookies))

            opener.open("http://login.rutracker.org/forum/login.php",
                "login_username={0}&login_password={1}&login=%C2%F5%EE%E4".format(login, password))

            self.__opener = opener
        except Exception as e:
            raise Error("Unable to login to rutracker.org: {0}.", e)


    def __request(self, url, data = None):
        """Sends a request."""

        if self.__opener is None:
            self.__login()

        max_per_second = 1
        min_difference = 1.0 / max_per_second
        if time.time() - self.__last_request_time < min_difference:
            time.sleep(self.__last_request_time + min_difference - time.time())

        try:
            return self.__opener.open(url, data).read().decode("cp1251")
        except Exception as e:
            raise Error("Unable to fetch page {0}: {1}.", url, e)
        finally:
            self.__last_request_time = time.time()


    def __start_search(self):
        """Starts torrent search."""

        try:
            page = self.__request("http://rutracker.org/forum/tracker.php",
                data = "prev_my=0&prev_new=0&prev_oop=0&f%5B%5D=46&f%5B%5D=2178&f%5B%5D=671&f%5B%5D=2177&f%5B%5D=251&f%5B%5D=97&f%5B%5D=851&f%5B%5D=821&f%5B%5D=2076&f%5B%5D=98&f%5B%5D=56&f%5B%5D=1469&f%5B%5D=2123&f%5B%5D=1280&f%5B%5D=876&f%5B%5D=752&f%5B%5D=1114&f%5B%5D=2380&f%5B%5D=1467&f%5B%5D=672&f%5B%5D=249&f%5B%5D=552&f%5B%5D=500&f%5B%5D=2112&f%5B%5D=1327&f%5B%5D=1468&o=1&s=2&tm=-1&pn=&nm=&submit=%CF%EE%E8%F1%EA")

            match = re.search(r'<a class="pg" href="tracker.php\?search_id=([^&]+)', page)
            if match is None:
                raise Error("Unable to obtain search id")

            self.__search_id = match.group(1)
        except Exception as e:
            raise Error("Failed to start torrent search: {0}.", e)



def get_new_torrents():
    """Gets new torrents info."""

    LOG.info("Search for new torrents...")

    # A regular expression for attribute name
    attribute_name_regex = "[a-zA-Z][-.a-zA-Z0-9:_]*"

    # A regular expression for tag attributes
    tag_attrs_regex = re.sub(r"\s*", "", r"""
        (?:\s+
          """ + attribute_name_regex + r"""
          (?:\s*=\s*
            (?:
              '[^']*'
              |"[^"]*"
              |[^'"/>\s]+
            )
          )?
        )*
    """)

    # A regular expression for a link to torrent page on http://rutracker.org
    torrent_regex = re.compile(
        r"<a" + tag_attrs_regex + r"""
            \s+class=(?:
                "([^"]+)"|
                '([^']+)'
            )
        """
            + tag_attrs_regex + r"""\s+href\s*=\s*["'][^'"]+/viewtopic\.php\?t=(\d+)["']"""
            + tag_attrs_regex + r"\s*>(.+?)</a>"

        r".+<td" + tag_attrs_regex + ur"""\s+title=['"]Добавлен['"]""" + tag_attrs_regex + r"\s*>\s*<u>(\d+)</u>"
    , re.IGNORECASE | re.DOTALL | re.VERBOSE)

    if not _DEVELOP_MODE:
        client = Rutracker()

    for page in xrange(0, 10):
        LOG.info("Getting page %s...", page)

        if _DEVELOP_MODE:
            torrents_page = open("./debug/{0}.html".format(page + 1)).read().decode("cp1251")
        else:
            torrents_page = client.search(page)

        # Scan all pages every time. It's not safe to skip them by last torrent
        # ID in the database because some of them might be hidden at the
        # previous run.

        counter = 0
        torrents_per_page = 50

        for torrent_html in torrents_page.split('<tr class="tCenter hl-tr">')[1:]:
            link_class, torrent_id, torrent_name, torrent_time = torrent_regex.search(torrent_html).group(1, 3, 4, 5)

            if _DEVELOP_MODE:
                torrent_time = time.time()

            link_class = link_class.split(" ")
            if "med" not in link_class or "tLink" not in link_class:
                continue

            torrent_id = int(torrent_id)
            torrent = coll("torrents").find_one({ "_id": torrent_id })

            if (
                torrent is None or
                torrent["name"] != torrent_name or
                torrent["time"] != torrent_time
            ):
                new_data = {
                    "name":        torrent_name,
                    "time":        torrent_time,
                    "fingerprint": rutracker.analysis.get_torrent_fingerprint(torrent_name),
                    "description": "",
                }

                coll("torrents").update({ "_id": torrent_id },
                    { "$set": new_data }, upsert = True, safe = True)

                LOG.info(u"New torrent #%s:%s [%s]: %s",
                    torrent_id, new_data["time"], new_data["fingerprint"], new_data["name"])
            else:
                LOG.debug(u"Torrent #%s:%s [%s]: %s",
                    torrent_id, torrent["time"], torrent["fingerprint"], torrent["name"])

            counter += 1

        if counter != torrents_per_page:
            LOG.error("Error while parsing page %s: got %s torrents instead of %s",
                page, counter, torrents_per_page)


def main():
    """The script's main function."""

    global _DEVELOP_MODE
    _DEVELOP_MODE = "--develop-mode" in sys.argv[1:]

    pycl.main.set_environment()
    pycl.log.setup(_DEVELOP_MODE)

    get_new_torrents()


if __name__ == "__main__":
    main()
